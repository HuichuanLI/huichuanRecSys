{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T11:55:33.138021Z",
     "start_time": "2021-02-20T11:55:33.126020Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def sparseFeature(feat, feat_num, embed_dim=4):\n",
    "    \"\"\"\n",
    "    create dictionary for sparse feature\n",
    "    :param feat: feature name\n",
    "    :param feat_num: the total number of sparse features that do not repeat\n",
    "    :param embed_dim: embedding dimension\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return {'feat': feat, 'feat_num': feat_num, 'embed_dim': embed_dim}\n",
    "\n",
    "\n",
    "def denseFeature(feat):\n",
    "    \"\"\"\n",
    "    create dictionary for dense feature\n",
    "    :param feat: dense feature name\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return {'feat': feat}\n",
    "\n",
    "\n",
    "def create_explicit_ml_1m_dataset(file, latent_dim=4, test_size=0.2):\n",
    "    \"\"\"\n",
    "    create the explicit dataset of movielens-1m\n",
    "    We took the last 20% of each user sorted by timestamp as the test dataset\n",
    "    Each of these samples contains UserId, MovieId, Rating, avg_score\n",
    "    :param file: dataset path\n",
    "    :param latent_dim: latent factor\n",
    "    :param test_size: ratio of test dataset\n",
    "    :return: user_num, item_num, train_df, test_df\n",
    "    \"\"\"\n",
    "    data_df = pd.read_csv(file, sep=\",\", header=0,engine='python',\n",
    "                     names=['UserId', 'MovieId', 'Rating', 'Timestamp'])\n",
    "    data_df[\"UserId\"].astype('int')\n",
    "    data_df['avg_score'] = data_df.groupby(by='UserId')['Rating'].transform('mean')\n",
    "    # feature columns\n",
    "    user_num, item_num = data_df['UserId'].max() + 1, data_df['MovieId'].max() + 1\n",
    "    feature_columns = [[denseFeature('avg_score')],\n",
    "                       [sparseFeature('user_id', user_num, latent_dim),\n",
    "                        sparseFeature('item_id', item_num, latent_dim)]]\n",
    "    # split train dataset and test dataset\n",
    "    watch_count = data_df.groupby(by='UserId')['MovieId'].agg('count')\n",
    "    test_df = pd.concat([\n",
    "        data_df[data_df.UserId == i].iloc[int(0.8 * watch_count[i]):] for i in tqdm(watch_count.index)], axis=0)\n",
    "    test_df = test_df.reset_index()\n",
    "    train_df = data_df.drop(labels=test_df['index'])\n",
    "    train_df = train_df.drop(['Timestamp'], axis=1).sample(frac=1.).reset_index(drop=True)\n",
    "    test_df = test_df.drop(['index', 'Timestamp'], axis=1).sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "    train_X = [train_df['avg_score'].values, train_df[['UserId', 'MovieId']].values]\n",
    "    train_y = train_df['Rating'].values.astype('int32')\n",
    "    test_X = [test_df['avg_score'].values, test_df[['UserId', 'MovieId']].values]\n",
    "    test_y = test_df['Rating'].values.astype('int32')\n",
    "    return feature_columns, (train_X, train_y), (test_X, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T11:56:59.021212Z",
     "start_time": "2021-02-20T11:55:33.664515Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29776/29776 [01:02<00:00, 479.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[{'feat': 'avg_score'}],\n",
       "  [{'feat': 'user_id', 'feat_num': 30001, 'embed_dim': 4},\n",
       "   {'feat': 'item_id', 'feat_num': 1001, 'embed_dim': 4}]],\n",
       " ([array([3.3125    , 3.53618421, 3.91082803, ..., 3.55769231, 3.25      ,\n",
       "          2.71559633]), array([[15157,   491],\n",
       "          [ 5102,   261],\n",
       "          [  394,    30],\n",
       "          ...,\n",
       "          [26495,   145],\n",
       "          [24563,   588],\n",
       "          [ 3538,   289]])], array([3, 5, 4, ..., 3, 4, 4], dtype=int32)),\n",
       " ([array([3.5       , 3.3       , 2.83846154, ..., 3.22115385, 4.09090909,\n",
       "          4.17592593]), array([[17552,   858],\n",
       "          [17936,   858],\n",
       "          [19212,   913],\n",
       "          ...,\n",
       "          [16607,   648],\n",
       "          [24515,   912],\n",
       "          [21938,   899]])], array([5, 5, 2, ..., 2, 5, 5], dtype=int32)))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_explicit_ml_1m_dataset(\"/Users/hui/Desktop/python/recommend/huichuanRecSys/spark_test/resources/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
